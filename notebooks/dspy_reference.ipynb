{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccac6fa1",
   "metadata": {},
   "source": [
    "#### Ensuring Factual Correctness using Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class FactualityJudge(dspy.Signature):\n",
    "    \"\"\"Determine if a statement is factually accurate.\"\"\"\n",
    "    statement: str = dspy.InputField()\n",
    "    is_factual: bool = dspy.OutputField()\n",
    "\n",
    "factuality_judge = dspy.ChainOfThought(FactualityJudge)\n",
    "\n",
    "def factuality_reward(args, pred: dspy.Prediction) -> float:\n",
    "    statement = pred.answer    \n",
    "    result = factuality_judge(statement)    \n",
    "    return 1.0 if result.is_factual else 0.0\n",
    "\n",
    "refined_qa = dspy.Refine(\n",
    "    module=dspy.ChainOfThought(\"question -> answer\"),\n",
    "    N=3,\n",
    "    reward_fn=factuality_reward,\n",
    "    threshold=1.0\n",
    ")\n",
    "\n",
    "result = refined_qa(question=\"Tell me about Belgium's capital city.\")\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e127ec1",
   "metadata": {},
   "source": [
    "#### Controlling Response Length using BestOfN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f592c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "def ideal_length_reward(args, pred: dspy.Prediction) -> float:\n",
    "    \"\"\"\n",
    "    Reward the summary for being close to 75 words with a tapering off for longer summaries.\n",
    "    \"\"\"\n",
    "    word_count = len(pred.summary.split())\n",
    "    distance = abs(word_count - 75)\n",
    "    return max(0.0, 1.0 - (distance / 125))\n",
    "\n",
    "optimized_summarizer = dspy.BestOfN(\n",
    "    module=dspy.ChainOfThought(\"text -> summary\"),\n",
    "    N=50,\n",
    "    reward_fn=ideal_length_reward,\n",
    "    threshold=0.9\n",
    ")\n",
    "\n",
    "result = optimized_summarizer(\n",
    "    text=\"[Long text to summarize...]\"\n",
    ")\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a9c88",
   "metadata": {},
   "source": [
    "#### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "DOCS = {}\n",
    "\n",
    "def search(query: str, k: int) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
    "    results = [x['text'] for x in results]\n",
    "\n",
    "    for result in results:\n",
    "        title, text = result.split(\" | \", 1)\n",
    "        DOCS[title] = text\n",
    "\n",
    "    return results\n",
    "\n",
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Returns top-5 results and then the titles of the top-5 to top-30 results.\"\"\"\n",
    "\n",
    "    topK = search(query, 30)\n",
    "    titles, topK = [f\"`{x.split(' | ')[0]}`\" for x in topK[5:30]], topK[:5]\n",
    "    return topK + [f\"Other retrieved pages have titles: {', '.join(titles)}.\"]\n",
    "\n",
    "def lookup_wikipedia(title: str) -> str:\n",
    "    \"\"\"Returns the text of the Wikipedia page, if it exists.\"\"\"\n",
    "\n",
    "    if title in DOCS:\n",
    "        return DOCS[title]\n",
    "\n",
    "    results = [x for x in search(title, 10) if x.startswith(title + \" | \")]\n",
    "    if not results:\n",
    "        return f\"No Wikipedia page found for title: {title}\"\n",
    "    return results[0]\n",
    "\n",
    "\n",
    "instructions = \"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\"\n",
    "signature = dspy.Signature(\"claim -> titles: list[str]\", instructions)\n",
    "react = dspy.ReAct(signature, tools=[search_wikipedia, lookup_wikipedia], max_iters=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3add0eb",
   "metadata": {},
   "source": [
    "#### Multi-Hop RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "DOCS = {}\n",
    "\n",
    "def search(query: str, k: int) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
    "    results = [x['text'] for x in results]\n",
    "\n",
    "    for result in results:\n",
    "        title, text = result.split(\" | \", 1)\n",
    "        DOCS[title] = text\n",
    "\n",
    "    return results\n",
    "\n",
    "class Hop(dspy.Module):\n",
    "    def __init__(self, num_docs=10, num_hops=4):\n",
    "        self.num_docs, self.num_hops = num_docs, num_hops\n",
    "        self.generate_query = dspy.ChainOfThought('claim, notes -> query')\n",
    "        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')\n",
    "\n",
    "    def forward(self, claim: str) -> list[str]:\n",
    "        notes = []\n",
    "        titles = []\n",
    "\n",
    "        for _ in range(self.num_hops):\n",
    "            query = self.generate_query(claim=claim, notes=notes).query\n",
    "            context = search(query, k=self.num_docs)\n",
    "            prediction = self.append_notes(claim=claim, notes=notes, context=context)\n",
    "            notes.extend(prediction.new_notes)\n",
    "            titles.extend(prediction.titles)\n",
    "        \n",
    "        return dspy.Prediction(notes=notes, titles=list(set(titles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0491f6c",
   "metadata": {},
   "source": [
    "#### Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class PeopleExtraction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
    "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
    "    \"\"\"\n",
    "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
    "    extracted_people: list[str] = dspy.OutputField(desc=\"all tokens referring to specific people extracted from the tokenized text\")\n",
    "\n",
    "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046ded0",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from typing import Literal\n",
    "\n",
    "class Categorize(dspy.Signature):\n",
    "    \"\"\"Classify historic events.\"\"\"\n",
    "\n",
    "    event: str = dspy.InputField()\n",
    "    category: Literal[\n",
    "        \"Wars and Conflicts\",\n",
    "        \"Politics and Governance\",\n",
    "        \"Science and Innovation\",\n",
    "        \"Cultural and Artistic Movements\",\n",
    "        \"Exploration and Discovery\",\n",
    "        \"Economic Events\",\n",
    "        \"Social Movements\",\n",
    "        \"Man-Made Disasters and Accidents\",\n",
    "        \"Natural Disasters and Climate\",\n",
    "        \"Sports and Entertainment\",\n",
    "        \"Famous Personalities and Achievements\"\n",
    "    ] = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "classify = dspy.Predict(Categorize)\n",
    "\n",
    "# Here is how we call this module\n",
    "classification = classify(event=\"[YOUR HISTORIC EVENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cbc9dd",
   "metadata": {},
   "source": [
    "### Advanced Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "# from func_timeout import func_set_timeout\n",
    "\n",
    "def fn_metadata(func):\n",
    "    signature = inspect.signature(func)\n",
    "    docstring = inspect.getdoc(func) or \"No docstring.\"\n",
    "    return dict(function_name=func.__name__, arguments=str(signature), docstring=docstring)\n",
    "\n",
    "def wrap_function_with_timeout(fn):\n",
    "    # @func_set_timeout(10)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return {\"return_value\": fn(*args, **kwargs), \"errors\": None}\n",
    "        except Exception as e:\n",
    "            return {\"return_value\": None, \"errors\": str(e)}\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class Agent(dspy.Module):\n",
    "    def __init__(self, max_steps=5):\n",
    "        self.max_steps = max_steps\n",
    "        instructions = \"For the final answer, produce short (not full sentence) answers in which you format dates as YYYY-MM-DD, names as Firstname Lastname, and numbers without leading 0s.\"\n",
    "        signature = dspy.Signature('question, trajectory, functions -> next_selected_fn, args: dict[str, Any]', instructions)\n",
    "        self.react = dspy.ChainOfThought(signature)\n",
    "\n",
    "    def forward(self, question, functions):\n",
    "        tools = {fn_name: fn_metadata(fn) for fn_name, fn in functions.items()}\n",
    "        trajectory = []\n",
    "\n",
    "        for _ in range(self.max_steps):\n",
    "            pred = self.react(question=question, trajectory=trajectory, functions=tools)\n",
    "            selected_fn = pred.next_selected_fn.strip('\"').strip(\"'\")\n",
    "            fn_output = wrap_function_with_timeout(functions[selected_fn])(**pred.args)\n",
    "            trajectory.append(dict(reasoning=pred.reasoning, selected_fn=selected_fn, args=pred.args, **fn_output))\n",
    "\n",
    "            if selected_fn == \"finish\":\n",
    "                break\n",
    "\n",
    "        return dspy.Prediction(answer=fn_output.get(\"return_value\", ''), trajectory=trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c6083",
   "metadata": {},
   "source": [
    "#### [Tool Retriever](https://www.databricks.com/blog/optimizing-databricks-llm-pipelines-dspy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf274fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class ToolChoice(dspy.Signature):\n",
    "   \"\"\"Determines a tool to choose from a list of tools based on a query\"\"\"\n",
    "\n",
    "   list_of_tools = dspy.InputField(desc=\"list of tools available to the agent\")\n",
    "   query = dspy.InputField()\n",
    "   selected_tool = dspy.OutputField(desc=\"returns a single tool based on the query from the list_of_tools input\")\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "   \"\"\"Answer questions with informative summary of an answer to user's question.\"\"\"\n",
    "\n",
    "   context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "   question = dspy.InputField()\n",
    "   answer = dspy.OutputField(desc=\"informative summary of an answer to user's question\")\n",
    "\n",
    "class ToolRetriever(dspy.Module):\n",
    "   def __init__(self):\n",
    "       self.generate_query = dspy.ChainOfThought(\"context, question -> query\")\n",
    "       self.choose_tool = dspy.ChainOfThought(ToolChoice)\n",
    "       self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "       self.tools = \"[answer_payroll_faq, irrelevant_content]\"\n",
    "\n",
    "\n",
    "   def irrelevant_content(self):\n",
    "       return \"Ask something else.\"\n",
    "\n",
    "\n",
    "   def forward(self, question):\n",
    "       client = OpenAI(api_key=openai_api_key)\n",
    "       retrieve = DatabricksRM()\n",
    "\n",
    "\n",
    "       context = []\n",
    "       query_output = self.generate_query(context = context, question=question)\n",
    "       tool_choice = self.choose_tool(list_of_tools=self.tools, query=query_output.query)\n",
    "\n",
    "\n",
    "       if tool_choice.selected_tool == \"irrelevant_content\":\n",
    "           return self.irrelevant_content()      \n",
    "       else:\n",
    "           search_query_embedding = client.embeddings.create(model=\"text-embedding-ada-002\", input=[question]).data[0].embedding\n",
    "           retrieved_context = retrieve(search_query_embedding, 1)\n",
    "\n",
    "\n",
    "           context += retrieved_context\n",
    "           return self.generate_answer(context=context, question=question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
